<!DOCTYPE html>
<html>
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis/4.20.1/vis.css" type="text/css" />
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/vis/4.20.1/vis-network.min.js"> </script>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script src="https://cdn.plot.ly/plotly-2.12.1.min.js"></script>
        <script src="../static/scripts/indexScript.js"></script>
        <script src="../static/scripts/drawGraph.js"></script>
        <script src="../static/scripts/drawPlot.js"></script>
        <script src="../static/scripts/guideScript.js"></script>
        <script src="../static/scripts/notify.js"></script>
        <link rel="stylesheet" href="../static/stylesheets/guideStyle.css">
        <link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
        <link rel="stylesheet" href="../static/stylesheets/generalStyle.css">
        <title>NNViz</title>
    </head>
    <body>
        <div id="navbarDiv">
            <nav class="navbar navbar-expand-lg" id="navbar">
                <div class="logo">
                    <img src="../static/images/NNViz%20Logo%202.png" width="200" alt="" id="logo">
                </div>
                <div class="navbar-collapse collapse w-100 order-1 order-md-0 dual-collapse2" id="navbarSupportedContent">
                    <ul class="navbar-nav me-auto">
                        <li class="nav-item">
                            <a class="nav-link" id="homeLink" href="/">Home</a>
                        </li>
                                                <li class="nav-item">
                            <a class="nav-link" id="homeLink" href="/guide">Guide</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" id="homeLink" href="/train">Train</a>
                        </li>
                    </ul>
                </div>
            </nav>
        </div>
        <div class="header">
            <h2>A brief introduction to <b>Neural Networks</b></h2>
            <h2><a href="/guide/1"><button class="btn-primary btn">Next Step</button></a></h2>
        </div>
        <div id="content">
            <div id="why-div" class="introduction">

                <br>
                <h4><b>Machine Learning</b> Concepts</h4>
                <br>
                <ul>
                    <li>
                        <h5>
                            <b>Machine Learning</b> is the field of <b>Artificial Intelligence</b> that studies computer algorithms able to learn from input data with the purpose of making
                            accurate predictions on new, unseen data. In other words, the goal of these algorithms, that have as output <b>models</b>, is to generalize on past data.
                        </h5>
                    </li>
                    <li>
                        <h5>
                            These <b>models</b> consist of a set of <b>parameters</b>, often called <b>weights</b>, that, during the training process, are adjusted. The training is conducted in <b>epochs</b>.
                            An epoch is done after all the instances of the training dataset have been fed to the model.
                        </h5>
                    </li>
                    <li>
                        <h5>
                            A different set of parameters, called <b>hyper-parameters</b>, are used to control the training process.
                        </h5>
                    </li>
                </ul>


                <br>
                <h4>What are <b>Neural Networks</b>?</h4>
                <br>
                <ul>
                    <li>
                        <h5>
                            The field of <b>Neural Networks</b> is a subset of <b>Machine Learning</b> that studies networks are inspired by the structure and function of the brain, by mimicking
                            the way the biologic neurons signal to one another.
                        </h5>
                    </li>
                    <li>
                        <h5>
                            Neural networks, also known as artificial neural networks, are comprised of <b>neurons</b>, often called <b>nodes</b>.
                        </h5>
                    </li>
                    <li>
                        <h5>
                            The simplest kind of neural network is the <b>perceptron</b> network, which consists of a single layer containing only one neuron. The inputs are fed directly into this neuron
                            via a series of weights. The sum of the products between each input and its respective weight is computed and if the value of the sum is above some threshold (usually \(0\))
                            the neuron fires and outputs the activated value (typically \(1\)). Otherwise, it outputs the deactivated value (typically \(-1\) or \(0\)). Combining more than one of
                            the perceptron neuron results in a <b>single-layer perceptron</b> network.
                        </h5>
                        <br>
                        <figure>
                            <div id="perceptron-div" class="nn-graph-div"></div>
                            <figcaption>
                                The Perceptron Network.
                            </figcaption>
                        </figure>
                        <br>
                        <h5>
                            You can see above that the perceptron applies a function <i>f</i> on the <i>z</i>, the sum of the products between each input and its weight. These functions used by neurons are called
                            <b>activation functions</b>, and their outputs represent the output of the neuron. In the case of the perceptron, the activation function used is the <b>step function</b>.
                        </h5>
                    </li>
                    <li>
                        <h5>
                            Because it is described by a linear equation, the perceptron is a <b>linear classifier</b>. Therefore, in a two-dimensional space, the perceptron is described by a line, while in space
                            with 3 or more dimensions the perceptron is described by a hyperplane.
                        </h5>
                        <h5>
                            Being a linear classifier, the perceptron can only classify <b>linearly separable</b> datasets.
                        </h5>
                        <div class="columns-div">
                            <figure class="plot-div">
                                <div id="plot-div-perceptron_AND" ></div>
                                <figcaption>
                                    The Perceptron, being a linear classifier, successfully learns the AND function, as its graph is linearly separable.
                                </figcaption>
                            </figure>
                            <figure class="plot-div">
                                <div id="plot-div-perceptron_XOR" ></div>
                                <figcaption>
                                    As for the XOR function, because its graph is not linearly separable, the Perceptron is unable to classify it correctly.
                                </figcaption>
                            </figure>
                        </div>
                        <br>
                    </li>
                    <li>
                        <h5>
                            The most common type of neural networks architectures is the <b>feed-forward</b> (also known as the <b>multi-layer perceptron</b>).
                            These networks are composed of at least three <b>layers</b> of neurons. Each node from one layer is connected through <b>weighted edges</b> to all the neurons on the next layer.
                            These type of networks is the heart of <b>Deep Learning</b>.
                        </h5>
                        <figure>
                            <div id="general-nn" class="nn-graph-div"></div>
                            <figcaption>
                                General depiction of feed-forward neural network: directed graphs, where each node represents neuron, and each edge represents a weighted link between them (i.e. every connection or edge
                                between a neuron on a layer and another has an associated weight to it)<br>
                                It can be observed that the network is organised in layers. It starts with the input layer, colored in blue. The last layer (rightmost one), is the output layer, also colored in blue.
                                The ones in the middle, colored in green, are the hidden layers.
                            </figcaption>
                        </figure>
                    </li>
                </ul>
                <br>
            </div>
        </div>
    </body>
</html>